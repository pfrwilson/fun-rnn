{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ssd003/home/pwilson/projects/fun-rnn\n"
     ]
    }
   ],
   "source": [
    "%cd /h/pwilson/projects/fun-rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import TrainableGPTModel\n",
    "import json \n",
    "import torch\n",
    "from torchzero.utils.tokenizer import Tokenizer\n",
    "from dataset import TextFileDataset\n",
    "\n",
    "with open('vocab_1024.json') as f: \n",
    "    vocab = json.load(f)\n",
    "\n",
    "d = TextFileDataset('data/bible.txt', 100000)\n",
    "dl = torch.utils.data.DataLoader(d, batch_size=1, shuffle=True)\n",
    "\n",
    "tokenizer = Tokenizer(vocab)\n",
    "tokenizer.add_token('<PAD>')\n",
    "tokenizer.add_token('<START>')\n",
    "model = TrainableGPTModel(4, 4, 512, 764, 0.1, tokenizer, max_len=20000).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import prepare_batch\n",
    "batch = next(iter(dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncating\n",
      "500\n",
      "torch.Size([1, 53151])\n",
      "torch.Size([1, 500])\n"
     ]
    }
   ],
   "source": [
    "from train import prepare_batch\n",
    "batch = next(iter(dl))\n",
    "\n",
    "X = prepare_batch(batch, tokenizer, max_len=500)\n",
    "X = X.to('cuda')\n",
    "\n",
    "targets = X[:, 1:]  # shift inputs forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 500])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X = model.embeddings(X)\n",
    "B, N, D = X.shape\n",
    "mask = torch.tril(torch.ones(N, N)).repeat(B, model.n_heads, 1, 1)\n",
    "X, _ = model.transformer(X, mask)\n",
    "X = model.classifier(X)\n",
    "\n",
    "X = X[:, :-1, :]  # truncate outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 499, 1027])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "truncating\n",
      "20000\n",
      "torch.Size([1, 54205])\n",
      "torch.Size([1, 20000])\n"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 5.96 GiB (GPU 0; 14.76 GiB total capacity; 9.80 GiB already allocated; 2.41 GiB free; 10.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m get_ipython()\u001b[39m.\u001b[39;49mrun_cell_magic(\u001b[39m'\u001b[39;49m\u001b[39mprun\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mmodel.step(batch)\u001b[39;49m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2478\u001b[0m, in \u001b[0;36mInteractiveShell.run_cell_magic\u001b[0;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbuiltin_trap:\n\u001b[1;32m   2477\u001b[0m     args \u001b[39m=\u001b[39m (magic_arg_s, cell)\n\u001b[0;32m-> 2478\u001b[0m     result \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2480\u001b[0m \u001b[39m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2481\u001b[0m \u001b[39m# when using magics with decodator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2482\u001b[0m \u001b[39m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(fn, magic\u001b[39m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[39mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/IPython/core/magics/execution.py:298\u001b[0m, in \u001b[0;36mExecutionMagics.prun\u001b[0;34m(self, parameter_s, cell)\u001b[0m\n\u001b[1;32m    296\u001b[0m     arg_str \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m cell\n\u001b[1;32m    297\u001b[0m arg_str \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshell\u001b[39m.\u001b[39mtransform_cell(arg_str)\n\u001b[0;32m--> 298\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_with_profiler(arg_str, opts, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshell\u001b[39m.\u001b[39;49muser_ns)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/IPython/core/magics/execution.py:320\u001b[0m, in \u001b[0;36mExecutionMagics._run_with_profiler\u001b[0;34m(self, code, opts, namespace)\u001b[0m\n\u001b[1;32m    318\u001b[0m prof \u001b[39m=\u001b[39m profile\u001b[39m.\u001b[39mProfile()\n\u001b[1;32m    319\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m     prof \u001b[39m=\u001b[39m prof\u001b[39m.\u001b[39;49mrunctx(code, namespace, namespace)\n\u001b[1;32m    321\u001b[0m     sys_exit \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mSystemExit\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/cProfile.py:100\u001b[0m, in \u001b[0;36mProfile.runctx\u001b[0;34m(self, cmd, globals, locals)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39menable()\n\u001b[1;32m     99\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 100\u001b[0m     exec(cmd, \u001b[39mglobals\u001b[39;49m, \u001b[39mlocals\u001b[39;49m)\n\u001b[1;32m    101\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdisable()\n",
      "File \u001b[0;32m<string>:1\u001b[0m\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/fun-rnn/train.py:188\u001b[0m, in \u001b[0;36mTrainableGPTModel.step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    186\u001b[0m B, N, D \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    187\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(N, N))\u001b[39m.\u001b[39mrepeat(B, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_heads, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m X, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(X, mask)\n\u001b[1;32m    189\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(X)\n\u001b[1;32m    191\u001b[0m X \u001b[39m=\u001b[39m X[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]  \u001b[39m# truncate outputs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/torchzero/torchzero/nn/transformer.py:127\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m    124\u001b[0m attentions \u001b[39m=\u001b[39m [] \n\u001b[1;32m    126\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers): \n\u001b[0;32m--> 127\u001b[0m     attn_layer_out, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn_blocks[i](X, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    128\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_layernorms[i](X \u001b[39m+\u001b[39m attn_layer_out)\n\u001b[1;32m    130\u001b[0m     ff_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_forward_blocks[i](X)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/torchzero/torchzero/nn/transformer.py:68\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m     65\u001b[0m K_t \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(K, \u001b[39m\"\u001b[39m\u001b[39mb n (h d_k) -> b h d_k n\u001b[39m\u001b[39m\"\u001b[39m, d_k\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_k)\n\u001b[1;32m     66\u001b[0m V \u001b[39m=\u001b[39m einops\u001b[39m.\u001b[39mrearrange(V, \u001b[39m\"\u001b[39m\u001b[39mb n (h d_v) -> b h n d_v\u001b[39m\u001b[39m\"\u001b[39m, d_v\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39md_v)\n\u001b[0;32m---> 68\u001b[0m attn_scores \u001b[39m=\u001b[39m (Q \u001b[39m@\u001b[39;49m K_t \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscale)\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \n\u001b[1;32m     70\u001b[0m     attn_scores[mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mINF\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 5.96 GiB (GPU 0; 14.76 GiB total capacity; 9.80 GiB already allocated; 2.41 GiB free; 10.25 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF"
     ]
    }
   ],
   "source": [
    "%%prun \n",
    "model.step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train_epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                      \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_epoch(dl, model, tokenizer, optimizer)\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/fun-rnn/train.py:458\u001b[0m, in \u001b[0;36mtrain_epoch\u001b[0;34m(loader, model, tokenizer, optimizer)\u001b[0m\n\u001b[1;32m    455\u001b[0m model\u001b[39m.\u001b[39mtrain()\n\u001b[1;32m    457\u001b[0m \u001b[39mfor\u001b[39;00m iteration, batch \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(tqdm(loader, leave\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)):\n\u001b[0;32m--> 458\u001b[0m     loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mstep(batch)\n\u001b[1;32m    459\u001b[0m     total \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    461\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/fun-rnn/train.py:188\u001b[0m, in \u001b[0;36mTrainableGPTModel.step\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    186\u001b[0m B, N, D \u001b[39m=\u001b[39m X\u001b[39m.\u001b[39mshape\n\u001b[1;32m    187\u001b[0m mask \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mtril(torch\u001b[39m.\u001b[39mones(N, N))\u001b[39m.\u001b[39mrepeat(B, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_heads, \u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m X, _ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransformer(X, mask)\n\u001b[1;32m    189\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclassifier(X)\n\u001b[1;32m    191\u001b[0m X \u001b[39m=\u001b[39m X[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, :]  \u001b[39m# truncate outputs\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/torchzero/torchzero/nn/transformer.py:130\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m    127\u001b[0m attentions \u001b[39m=\u001b[39m [] \n\u001b[1;32m    129\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_layers): \n\u001b[0;32m--> 130\u001b[0m     attn_layer_out, attn \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mattn_blocks[i](X, mask\u001b[39m=\u001b[39;49mmask)\n\u001b[1;32m    131\u001b[0m     X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mattn_layernorms[i](X \u001b[39m+\u001b[39m attn_layer_out)\n\u001b[1;32m    133\u001b[0m     ff_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeed_forward_blocks[i](X)\n",
      "File \u001b[0;32m~/anaconda3/envs/torch2.0/lib/python3.10/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/ssd003/home/pwilson/projects/torchzero/torchzero/nn/transformer.py:75\u001b[0m, in \u001b[0;36mMultiHeadAttention.forward\u001b[0;34m(self, X, mask)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[39mif\u001b[39;00m mask \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m: \n\u001b[1;32m     73\u001b[0m     attn_scores[mask \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m-\u001b[39mINF\n\u001b[0;32m---> 75\u001b[0m attn \u001b[39m=\u001b[39m attn_scores\u001b[39m.\u001b[39;49msoftmax(\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m)\n\u001b[1;32m     76\u001b[0m attn_weighted_values \u001b[39m=\u001b[39m attn \u001b[39m@\u001b[39m V\n\u001b[1;32m     78\u001b[0m \u001b[39m# concatenate across head dim \u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epoch(dl, model, tokenizer, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         15626 function calls (15534 primitive calls) in 0.181 seconds\n",
      "\n",
      "   Ordered by: internal time\n",
      "\n",
      "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
      "        4    0.163    0.041    0.167    0.042 transformer.py:52(forward)\n",
      "        4    0.005    0.001    0.007    0.002 tokenizer.py:51(encode)\n",
      "       25    0.002    0.000    0.002    0.000 {built-in method torch._C._nn.linear}\n",
      "        1    0.002    0.002    0.002    0.002 {method 'repeat' of 'torch._C._TensorBase' objects}\n",
      "8472/8440    0.001    0.000    0.001    0.000 {built-in method builtins.len}\n",
      "     6211    0.001    0.000    0.001    0.000 {method 'append' of 'list' objects}\n",
      "       34    0.001    0.000    0.001    0.000 {method 'reshape' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.tensor}\n",
      "        1    0.000    0.000    0.170    0.170 transformer.py:125(forward)\n",
      "        1    0.000    0.000    0.181    0.181 <string>:1(<module>)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch.layer_norm}\n",
      "     63/3    0.000    0.000    0.170    0.057 module.py:1494(_call_impl)\n",
      "        2    0.000    0.000    0.000    0.000 tokenizer.py:35(<dictcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.ones}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.tril}\n",
      "        1    0.000    0.000    0.000    0.000 {method 'to' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.dropout}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'softmax' of 'torch._C._TensorBase' objects}\n",
      "       17    0.000    0.000    0.000    0.000 {method 'permute' of 'torch._C._TensorBase' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch._C._nn.cross_entropy_loss}\n",
      "        1    0.000    0.000    0.181    0.181 train.py:171(step)\n",
      "       17    0.000    0.000    0.001    0.000 einops.py:231(_apply_recipe)\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method torch.relu}\n",
      "      110    0.000    0.000    0.000    0.000 module.py:1601(__getattr__)\n",
      "       17    0.000    0.000    0.001    0.000 einops.py:357(reduce)\n",
      "       25    0.000    0.000    0.003    0.000 linear.py:113(forward)\n",
      "       63    0.000    0.000    0.000    0.000 {built-in method torch._C._get_tracing_state}\n",
      "       17    0.000    0.000    0.002    0.000 einops.py:424(rearrange)\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method torch.embedding}\n",
      "        1    0.000    0.000    0.008    0.008 train.py:260(prepare_batch)\n",
      "        8    0.000    0.000    0.000    0.000 functional.py:2500(layer_norm)\n",
      "       16    0.000    0.000    0.000    0.000 container.py:281(_get_abs_string_index)\n",
      "        8    0.000    0.000    0.001    0.000 container.py:215(forward)\n",
      "       16    0.000    0.000    0.000    0.000 container.py:290(__getitem__)\n",
      "        8    0.000    0.000    0.001    0.000 normalization.py:189(forward)\n",
      "       17    0.000    0.000    0.000    0.000 _backends.py:22(get_backend)\n",
      "        4    0.000    0.000    0.000    0.000 functional.py:1235(dropout)\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method builtins.sorted}\n",
      "       34    0.000    0.000    0.001    0.000 _backends.py:83(reshape)\n",
      "       17    0.000    0.000    0.000    0.000 _backends.py:79(shape)\n",
      "       17    0.000    0.000    0.000    0.000 einops.py:40(_reduce_axes)\n",
      "        1    0.000    0.000    0.181    0.181 {built-in method builtins.exec}\n",
      "        4    0.000    0.000    0.001    0.000 mlp.py:24(forward)\n",
      "        1    0.000    0.000    0.000    0.000 functional.py:2939(cross_entropy)\n",
      "       50    0.000    0.000    0.000    0.000 {built-in method builtins.isinstance}\n",
      "       17    0.000    0.000    0.000    0.000 _backends.py:258(is_appropriate_type)\n",
      "       32    0.000    0.000    0.000    0.000 container.py:311(__len__)\n",
      "        4    0.000    0.000    0.000    0.000 functional.py:1446(relu)\n",
      "        4    0.000    0.000    0.000    0.000 dropout.py:58(forward)\n",
      "       17    0.000    0.000    0.000    0.000 _backends.py:290(transpose)\n",
      "        4    0.000    0.000    0.000    0.000 container.py:315(__iter__)\n",
      "        4    0.000    0.000    0.000    0.000 activation.py:102(forward)\n",
      "       36    0.000    0.000    0.000    0.000 {method 'items' of 'dict' objects}\n",
      "        8    0.000    0.000    0.000    0.000 container.py:207(__iter__)\n",
      "        1    0.000    0.000    0.000    0.000 sparse.py:161(forward)\n",
      "        8    0.000    0.000    0.000    0.000 __init__.py:31(__get__)\n",
      "        1    0.000    0.000    0.000    0.000 functional.py:2109(embedding)\n",
      "        4    0.000    0.000    0.000    0.000 _VF.py:26(__getattr__)\n",
      "       17    0.000    0.000    0.000    0.000 typing.py:1737(cast)\n",
      "       10    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_variadic}\n",
      "       12    0.000    0.000    0.000    0.000 {built-in method builtins.iter}\n",
      "       17    0.000    0.000    0.000    0.000 {built-in method builtins.callable}\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch._C._has_torch_function_unary}\n",
      "        1    0.000    0.000    0.007    0.007 train.py:262(<listcomp>)\n",
      "        2    0.000    0.000    0.000    0.000 tokenizer.py:33(vocab2idx)\n",
      "        8    0.000    0.000    0.000    0.000 {built-in method torch._C._get_cudnn_enabled}\n",
      "       16    0.000    0.000    0.000    0.000 {built-in method _operator.index}\n",
      "        4    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
      "       12    0.000    0.000    0.000    0.000 {method 'values' of 'collections.OrderedDict' objects}\n",
      "       36    0.000    0.000    0.000    0.000 {method 'pop' of 'list' objects}\n",
      "        1    0.000    0.000    0.000    0.000 train.py:263(<listcomp>)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'size' of 'torch._C._TensorBase' objects}\n",
      "        4    0.000    0.000    0.000    0.000 {method 'insert' of 'list' objects}\n",
      "        4    0.000    0.000    0.000    0.000 linear.py:44(forward)\n",
      "        1    0.000    0.000    0.000    0.000 _reduction.py:7(get_enum)\n",
      "        1    0.000    0.000    0.000    0.000 {method 'disable' of '_lsprof.Profiler' objects}\n",
      "        1    0.000    0.000    0.000    0.000 {built-in method builtins.max}"
     ]
    }
   ],
   "source": [
    "%%prun\n",
    "model.step(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
